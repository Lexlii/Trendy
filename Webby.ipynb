{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRENDING CONTENT ON THE VERGE\n",
    "\n",
    "Catching up on your favourite trends can be quiet stressful. \n",
    "This is where our little application comes to help. \n",
    "With this tool, you can search for the most trending topics based on categories such as Science, Tech, Reviews\n",
    "and Entertainment all from the Verge website. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WEB SCRAPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_article = input(\"What topic do you want to search for?\")\n",
    "number_of_articles = int(input(\"How many articles do you want to search in?\"))\n",
    "url = 'https://www.theverge.com/' + n_article  \n",
    "artic = requests.get(url)\n",
    "html = artic.text\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "body = soup.find_all('div', class_='c-entry-box--compact c-entry-box--compact--article')\n",
    "\n",
    "article_contents = []\n",
    "list_links = []\n",
    "list_titles = []\n",
    "\n",
    "\n",
    "for i in range(number_of_articles):\n",
    "    if \"theverge\" not in body[i].find('a')['href']:\n",
    "        continue\n",
    "\n",
    "    link = body[i].find('a')['href']\n",
    "    list_links.append(link)\n",
    "\n",
    "    title = body[i].find('a').get_text()\n",
    "    list_titles.append(title)\n",
    "\n",
    "    article = requests.get(link)\n",
    "    article_body = article.text\n",
    "    soup_article = BeautifulSoup(article_body, 'html.parser')\n",
    "    bod = soup_article.find_all('div')\n",
    "    x = bod[0].find_all('p')\n",
    "\n",
    "    list_paragraphs = []\n",
    "    for j in range(0, len(x)):\n",
    "        paragraph = x[j].get_text()\n",
    "        list_paragraphs.append(paragraph)\n",
    "        final_article = ' '.join(list_paragraphs)\n",
    "    article_contents.append(final_article)\n",
    "\n",
    "\n",
    "article_contents[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find Only The Words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.RegexpTokenizer('\\w+')\n",
    "\n",
    "tokens = tokenizer.tokenize(str(article_contents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change All The Words To Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wording = [word.lower() for word in tokens]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download StopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = nltk.corpus.stopwords.words('english') + ['verge']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove All StopWords In Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "no_stopwords = [word for word in wording if word not in stop_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect The Top Most Common Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "word_count = Counter(no_stopwords)\n",
    "count = word_count.most_common(20)\n",
    "wc = [i[0] for i in count]\n",
    "wc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw A Frequency Distribution Of Common Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "freqDist = nltk.FreqDist(no_stopwords)\n",
    "freqDist.plot(20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "67e0cbc25fa4f5baaacba1240f401bc655b640f8e15cfc935dfee2e63491bdf4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
